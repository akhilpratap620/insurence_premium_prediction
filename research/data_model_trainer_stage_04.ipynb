{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\somit\\\\Downloads\\\\project_ineuron\\\\insurence_premium_prediction\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\somit\\\\Downloads\\\\project_ineuron\\\\insurence_premium_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_file_path: Path\n",
    "    base_accuracy: float\n",
    "    model_config_file_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurence_premium.constant import *\n",
    "from insurence_premium.util.common import (\n",
    "    read_yaml,\n",
    "    create_directories,\n",
    "    load_numpy_array_data,\n",
    ")\n",
    "from pathlib import Path\n",
    "from insurence_premium.entity import (\n",
    "    DataIngestionConfig,\n",
    "    DataValidationConfig,\n",
    "    DataTransformationConfig,\n",
    ")\n",
    "from insurence_premium import logger\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(\n",
    "        self,\n",
    "    ) -> DataIngestionConfig:\n",
    "        ingestion_config = self.config.data_ingestion\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(ingestion_config.root_dir),\n",
    "            raw_data=Path(ingestion_config.raw_data),\n",
    "            ingested_train_dir=Path(ingestion_config.ingested_train_dir),\n",
    "            ingested_test_dir=Path(ingestion_config.ingested_test_dir),\n",
    "        )\n",
    "        return data_ingestion_config\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        validation_config = self.config.data_validation\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=Path(validation_config.root_dir),\n",
    "            schema_file_path=Path(validation_config.schema_file_path),\n",
    "            report_file_path=Path(validation_config.report_file_path),\n",
    "            report_page_file_path=Path(validation_config.report_page_file_path),\n",
    "        )\n",
    "        return data_validation_config\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        try:\n",
    "            transformation_config = self.config.data_transformation\n",
    "            data_transformation_config = DataTransformationConfig(\n",
    "                root_dir=Path(transformation_config.root_dir),\n",
    "                transformed_train_file_path=Path(\n",
    "                    transformation_config.transformed_train_file_path\n",
    "                ),\n",
    "                transformed_test_file_path=Path(\n",
    "                    transformation_config.transformed_test_file_path\n",
    "                ),\n",
    "                preprocessing_dir=Path(transformation_config.preprocessing_dir),\n",
    "                preprocessing_file_path=Path(\n",
    "                    transformation_config.preprocessing_file_path\n",
    "                ),\n",
    "            )\n",
    "            return data_transformation_config\n",
    "            logging.info(f\"return: [{data_ingestion_config}]\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def get_model_trainer_config(self) -> DataModelTrainerConfig:\n",
    "        try:\n",
    "            model_trainer_config = self.config.data_model_trainer\n",
    "\n",
    "            data_model_trainer_config = DataModelTrainerConfig(\n",
    "                root_dir=Path(model_trainer_config.root_dir),\n",
    "                trained_model_file_path=Path(\n",
    "                    model_trainer_config.trained_model_file_path\n",
    "                ),\n",
    "                base_accuracy=model_trainer_config.base_accuracy,\n",
    "                model_config_file_path=Path(\n",
    "                    model_trainer_config.model_config_file_path\n",
    "                ),\n",
    "            )\n",
    "            return data_model_trainer_config\n",
    "            logger.info(f\"model trainer config : {data_model_trainer_config}\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def get_model_pusher_config(self):\n",
    "        try:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-30 14:21:23,109: INFO: common]: yaml file: config\\config.yaml loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigBox({'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'raw_data': 'artifacts/data_ingestion/raw_data/insurence.csv', 'ingested_train_dir': 'artifacts/data_ingestion/train/insurence.csv', 'ingested_test_dir': 'artifacts/data_ingestion/test/insurence.csv'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'report_file_path': 'artifacts/data_validation/report.json', 'report_page_file_path': 'artifacts/data_validation/report.html', 'schema_file_path': 'config/schema.yaml'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'transformed_train_file_path': 'artifacts/data_transformation/train/insurence.npz', 'transformed_test_file_path': 'artifacts/data_transformation/test/insurence.npz', 'preprocessing_dir': 'artifacts/data_transformation/preprocessed_file', 'preprocessing_file_path': 'artifacts/data_transformation/preprocessed_file/preprocessing.pkl'}, 'data_model_trainer': {'root_dir': 'artifacts/data_model_trainer', 'trained_model_file_path': 'artifacts/data_model_trainer/trained_model/model.pkl', 'base_accuracy': 0.6, 'model_config_file_path': 'config/model.yaml'}})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_yaml(path_to_yaml=Path(\"config/config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-30 14:21:23,897: INFO: common]: yaml file: config\\config.yaml loaded successfully\n",
      "[2023-03-30 14:21:23,903: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2023-03-30 14:21:23,907: INFO: common]: created directory at: artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataModelTrainerConfig(root_dir=WindowsPath('artifacts/data_model_trainer'), trained_model_file_path=WindowsPath('artifacts/data_model_trainer/trained_model/model.pkl'), base_accuracy=0.6, model_config_file_path=WindowsPath('config/model.yaml'))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfigurationManager().get_model_trainer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-30 14:21:24,375: INFO: common]: yaml file: config\\config.yaml loaded successfully\n",
      "[2023-03-30 14:21:24,379: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2023-03-30 14:21:24,384: INFO: common]: created directory at: artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': 5, 'verbose': 2}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con =ConfigurationManager()\n",
    "data_trainer_config=con.get_model_trainer_config()\n",
    "model_config_file_path=data_trainer_config.model_config_file_path\n",
    "m_i_c:dict=dict(ModelFactory.read_params(model_config_file_path)[GRID_SEARCH_KEY][PARAM_KEY])\n",
    "m_i_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingEstimatorModel:\n",
    "    def __init__(self, preprocessing_object, trained_model_object):\n",
    "        \"\"\"\n",
    "        TrainedModel constructor\n",
    "        preprocessing_object: preprocessing_object\n",
    "        trained_model_object: trained_model_object\n",
    "        \"\"\"\n",
    "        self.preprocessing_object = preprocessing_object\n",
    "        self.trained_model_object = trained_model_object\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        function accepts raw inputs and then transformed raw input using preprocessing_object\n",
    "        which gurantees that the inputs are in the same format as the training data\n",
    "        At last it perform prediction on transformed features\n",
    "        \"\"\"\n",
    "        transformed_feature = self.preprocessing_object.transform(X)\n",
    "        return self.trained_model_object.predict(transformed_feature)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{type(self.trained_model_object).__name__}()\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{type(self.trained_model_object).__name__}()\"\n",
    "\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ConfigurationManager):\n",
    "        self.config = ConfigurationManager()\n",
    "        self.data_trainer_config = self.config.get_model_trainer_config()\n",
    "        self.data_transformation_config = self.config.get_data_transformation_config()\n",
    "\n",
    "    def get_trained_model(self):\n",
    "        try:\n",
    "            logger.info(\"loading training and testing data sets\")\n",
    "            train_file_path = self.data_transformation_config.transformed_train_file_path\n",
    "            test_file_path = self.data_transformation_config.transformed_test_file_path\n",
    "\n",
    "            train_data = load_numpy_array_data(file_path=train_file_path)\n",
    "            test_data = load_numpy_array_data(file_path=test_file_path)\n",
    "            x_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "            x_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "            logger.info(\"train and test data generated for data training\")\n",
    "\n",
    "            model_config_file_path = self.data_trainer_config.model_config_file_path\n",
    "            logger.info(\"initializing model by using config filepath\")\n",
    "\n",
    "            model_factory = ModelFactory(config_file_path=model_config_file_path)\n",
    "\n",
    "            base_accuracy = self.data_trainer_config.base_accuracy\n",
    "            logger.info(f\"expected accuracy:{base_accuracy}\")\n",
    "\n",
    "            best_model = model_factory.get_best_model(x=x_train,y=y_train,base_accuracy=base_accuracy)\n",
    "            \n",
    "            logger.info(f\"Best model found on training dataset: {best_model}\")\n",
    "            \n",
    "            logger.info(f\"Extracting trained model list.\")\n",
    "            grid_searched_best_model_list:List[GridSearchedBestModel]=model_factory.grid_searched_best_model_list\n",
    "\n",
    "            model_list = [model.best_model for model in grid_searched_best_model_list ]\n",
    "            logger.info(f\"Evaluation all trained model on training and testing dataset both\")\n",
    "            metric_info:MetricInfoArtifact = evaluate_regression_model(model_list=model_list,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,base_accuracy=base_accuracy)\n",
    "\n",
    "            logger.info(f\"Best found model on both training and testing dataset.\")\n",
    "            preprocessing_obj=  load_object(file_path=self.data_transformation_config.preprocessing_file_path)\n",
    "            model_object = metric_info.model_object\n",
    "\n",
    "\n",
    "            trained_model_file_path=self.data_trainer_config.trained_model_file_path\n",
    "            housing_model = HousingEstimatorModel(preprocessing_object=preprocessing_obj,trained_model_object=model_object)\n",
    "            logger.info(f\"Saving model at path: {trained_model_file_path}\")\n",
    "            save_object(file_path=trained_model_file_path,obj=housing_model)\n",
    "            logger.info(f\"Saving model at path: {trained_model_file_path} is successfully done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SEARCH_KEY = \"grid_search\"\n",
    "MODULE_KEY = \"module\"\n",
    "CLASS_KEY = \"class\"\n",
    "PARAM_KEY = \"params\"\n",
    "MODEL_SELECTION_KEY = \"model_selection\"\n",
    "SEARCH_PARAM_GRID_KEY = \"search_param_grid\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "InitialisedModelDetail = namedtuple(\n",
    "    \"InitialisedModelDetail\",\n",
    "    [\"model_serial_number\", \"model\", \"param_grid_search\", \"model_name\"],\n",
    ")\n",
    "\n",
    "GridSearchedBestModel = namedtuple(\n",
    "    \"GridSearchedBestModel\",\n",
    "    [\n",
    "        \"model_serial_number\",\n",
    "        \"model\",\n",
    "        \"best_model\",\n",
    "        \"best_parameters\",\n",
    "        \"best_score\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "BestModel = namedtuple(\n",
    "    \"BestModel\",\n",
    "    [\n",
    "        \"model_serial_number\",\n",
    "        \"model\",\n",
    "        \"best_model\",\n",
    "        \"best_parameters\",\n",
    "        \"best_score\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "MetricInfoArtifact = namedtuple(\n",
    "    \"MetricInfoArtifact\",\n",
    "    [\n",
    "        \"model_name\",\n",
    "        \"model_object\",\n",
    "        \"train_rmse\",\n",
    "        \"test_rmse\",\n",
    "        \"train_accuracy\",\n",
    "        \"test_accuracy\",\n",
    "        \"model_accuracy\",\n",
    "        \"index_number\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFactory:\n",
    "    def __init__(self ,config_file_path:str):\n",
    "        self.config=ModelFactory.read_params(config_file_path)\n",
    "        self.grid_search_cv_module:str = self.config[GRID_SEARCH_KEY][MODULE_KEY]\n",
    "        self.grid_search_cv_class:str = self.config[GRID_SEARCH_KEY][CLASS_KEY]\n",
    "        self.grid_search_cv_property_data:dict = dict(self.config[GRID_SEARCH_KEY][PARAM_KEY])\n",
    "        self.models_initialization_config: dict = dict(self.config[MODEL_SELECTION_KEY])\n",
    "        self.initialised_model_list = None\n",
    "        self.grid_searched_best_model_list = None\n",
    "\n",
    "    @staticmethod\n",
    "    def read_params(file_path:str):\n",
    "        try:\n",
    "            with open(file_path) as file_obj:\n",
    "                config:dict =yaml.safe_load(file_obj)\n",
    "            return config    \n",
    "\n",
    "        except Exception as e:\n",
    "            raise e   \n",
    "\n",
    "    @staticmethod\n",
    "    def update_property_for_class(instance_obj:object ,property_data:dict):\n",
    "        try:\n",
    "            if not isinstance(property_data ,dict):\n",
    "                raise Exception(\"property_data required dict formate\")\n",
    "                print(proprty_data)\n",
    "            for key ,value in property_data.items():\n",
    "                setattr(instance_obj ,key ,value)\n",
    "                logger.info(f\"Executing:$ {str(instance_obj)}.{key}={value}\")\n",
    "            return instance_obj\n",
    "        except Exception as e:\n",
    "            raise e        \n",
    "\n",
    "    @staticmethod\n",
    "    def class_for_name(module_name:str ,class_name=str):\n",
    "        try:\n",
    "            module=importlib.import_module(module_name)\n",
    "            logger.info(f\"importing module:{module_name} with class:{class_name}\")\n",
    "            class_ref=getattr(module ,class_name)\n",
    "            return class_ref\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def get_initialised_model_list(self)->List[InitialisedModelDetail]:\n",
    "        try:\n",
    "            initialised_model_list=[]\n",
    "            for model_serial_number in self.models_initialization_config.keys():\n",
    "                model_initialization_config =self.models_initialization_config[model_serial_number]\n",
    "                model_obj_ref =ModelFactory.class_for_name(\n",
    "                    model_initialization_config[MODULE_KEY] ,\n",
    "                    model_initialization_config[CLASS_KEY])\n",
    "                model=model_obj_ref()\n",
    "\n",
    "                if PARAM_KEY in model_initialization_config:\n",
    "                    model_property_data=dict(model_initialization_config[PARAM_KEY]) \n",
    "                    model=ModelFactory.update_property_for_class(instance_obj=model ,property_data=model_property_data)\n",
    "                param_grid_search=model_initialization_config[SEARCH_PARAM_GRID_KEY]\n",
    "\n",
    "                model_name=f\"[{model_initialization_config[MODULE_KEY]}.{model_initialization_config[CLASS_KEY]}]\"\n",
    "\n",
    "                model_initialization_detail=InitialisedModelDetail(\n",
    "                    model_serial_number=model_serial_number,\n",
    "                    model=model,\n",
    "                    param_grid_search=param_grid_search,\n",
    "                    model_name=model_name,\n",
    "                    \n",
    "                )   \n",
    "\n",
    "                initialised_model_list.append(model_initialization_detail)\n",
    "            return initialised_model_list        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def execute_grid_search_operation(self,\n",
    "\n",
    "                                    initialised_model:InitialisedModelDetail ,\n",
    "                                    input_feature ,output_feature)->GridSearchedBestModel:\n",
    "        try:\n",
    "            grid_search_cv_ref=ModelFactory.class_for_name(module_name=self.grid_search_cv_module ,class_name=self.grid_search_cv_class)\n",
    "            grid_search_cv=grid_search_cv_ref(estimator=initialised_model.model ,param_grid=initialised_model.param_grid_search)\n",
    "            grid_search_cv=ModelFactory.update_property_for_class(instance_obj=grid_search_cv ,property_data=self.grid_search_cv_property_data)\n",
    "            grid_search_cv.fit(input_feature ,output_feature)\n",
    "\n",
    "            message = f'{\">>\"* 30} f\"Training {type(initialised_model.model).__name__}\" completed {\"<<\"*30}'\n",
    "            grid_searched_best_model = GridSearchedBestModel(model_serial_number=initialised_model.model_serial_number,\n",
    "                                                             model=initialised_model.model,\n",
    "                                                             best_model=grid_search_cv.best_estimator_,\n",
    "                                                             best_parameters=grid_search_cv.best_params_,\n",
    "                                                             best_score=grid_search_cv.best_score_\n",
    "                                                             )\n",
    "            \n",
    "            return grid_searched_best_model\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e                            \n",
    "    \n",
    "    def initiate_best_parameter_search_for_initialised_model(self, initialised_model: InitialisedModelDetail,\n",
    "                                                             input_feature,\n",
    "                                                             output_feature) -> GridSearchedBestModel:\n",
    "        \"\"\"\n",
    "        initiate_best_model_parameter_search(): function will perform paramter search operation and\n",
    "        it will return you the best optimistic  model with best paramter:\n",
    "        estimator: Model object\n",
    "        param_grid: dictionary of paramter to perform search operation\n",
    "        input_feature: your all input features\n",
    "        output_feature: Target/Dependent features\n",
    "        ================================================================================\n",
    "        return: Function will return a GridSearchOperation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.execute_grid_search_operation(initialised_model=initialised_model,\n",
    "                                                      input_feature=input_feature,\n",
    "                                                      output_feature=output_feature)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    def initiate_best_parameter_search_for_initialised_models(self,\n",
    "                                                              initialised_model_list: List[InitialisedModelDetail],\n",
    "                                                              input_feature,\n",
    "                                                              output_feature) -> List[GridSearchedBestModel]:\n",
    "\n",
    "        try:\n",
    "            self.grid_searched_best_model_list = []\n",
    "            for initialised_model_list in initialised_model_list:\n",
    "                grid_searched_best_model = self.initiate_best_parameter_search_for_initialised_model(\n",
    "                    initialised_model=initialised_model_list,\n",
    "                    input_feature=input_feature,\n",
    "                    output_feature=output_feature\n",
    "                )\n",
    "                self.grid_searched_best_model_list.append(grid_searched_best_model)\n",
    "            return self.grid_searched_best_model_list\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    @staticmethod\n",
    "    def get_best_model_from_grid_searched_best_model_list(grid_searched_best_model_list:List[GridSearchedBestModel] ,base_accuracy=0.6)->BestModel:\n",
    "        try:\n",
    "            best_model=None\n",
    "            for grid_search_best_model in grid_searched_best_model_list:\n",
    "                if grid_search_best_model.best_score > base_accuracy:\n",
    "                    logger.info(\"Acceptable model found:{grid_search_best_model}\")\n",
    "                    best_model=grid_search_best_model\n",
    "\n",
    "\n",
    "            if not best_model:\n",
    "                raise Exception(\"No better model has accuracy than base model\")  \n",
    "            logger.info(f\"best model found:{best_model}\")     \n",
    "        except Exception as e:\n",
    "            raise e                \n",
    "\n",
    "    def get_best_model(self ,x,y,base_accuracy=0.6):\n",
    "        try:\n",
    "            initialised_model=self.get_initialised_model_list()\n",
    "            grid_searched_best_model_list = self.initiate_best_parameter_search_for_initialised_models(\n",
    "                initialised_model_list=initialised_model,\n",
    "                input_feature=x,\n",
    "                output_feature=y\n",
    "            )\n",
    "            return ModelFactory.get_best_model_from_grid_searched_best_model_list(grid_searched_best_model_list=grid_searched_best_model_list,base_accuracy=0.6)\n",
    "        except Exception as e:\n",
    "            raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SEARCH_KEY = 'grid_search'\n",
    "MODULE_KEY = 'module'\n",
    "CLASS_KEY = 'class'\n",
    "PARAM_KEY = 'params'\n",
    "MODEL_SELECTION_KEY = 'model_selection'\n",
    "SEARCH_PARAM_GRID_KEY = \"search_param_grid\"\n",
    "\n",
    "\n",
    "def evaluate_regression_model(model_list: list, x_train:np.ndarray, y_train:np.ndarray, x_test:np.ndarray, y_test:np.ndarray, base_accuracy:float=0.6) -> MetricInfoArtifact:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function compare multiple regression model return best model\n",
    "    Params:\n",
    "    model_list: List of model\n",
    "    X_train: Training dataset input feature\n",
    "    y_train: Training dataset target feature\n",
    "    X_test: Testing dataset input feature\n",
    "    y_test: Testing dataset input feature\n",
    "    return\n",
    "    It retured a named tuple\n",
    "    \n",
    "    MetricInfoArtifact = namedtuple(\"MetricInfo\",\n",
    "                                [\"model_name\", \"model_object\", \"train_rmse\", \"test_rmse\", \"train_accuracy\",\n",
    "                                 \"test_accuracy\", \"model_accuracy\", \"index_number\"])\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        index_number = 0\n",
    "        metric_info_artifact = None\n",
    "        for model in model_list:\n",
    "            model_name = str(model)  #getting model name based on model object\n",
    "            logger.info(f\"{'>>'*30}Started evaluating model: [{type(model).__name__}] {'<<'*30}\")\n",
    "            \n",
    "            #Getting prediction for training and testing dataset\n",
    "            y_train_pred = model.predict(x_train)\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            #Calculating r squared score on training and testing dataset\n",
    "            train_acc = r2_score(y_train, y_train_pred)\n",
    "            test_acc = r2_score(y_test, y_test_pred)\n",
    "            \n",
    "            #Calculating mean squared error on training and testing dataset\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            # Calculating harmonic mean of train_accuracy and test_accuracy\n",
    "            model_accuracy = (2 * (train_acc * test_acc)) / (train_acc + test_acc)\n",
    "            diff_test_train_acc = abs(test_acc - train_acc)\n",
    "            \n",
    "            #logging all important metric\n",
    "            logger.info(f\"{'>>'*30} Score {'<<'*30}\")\n",
    "            logger.info(f\"Train Score\\t\\t Test Score\\t\\t Average Score\")\n",
    "            logger.info(f\"{train_acc}\\t\\t {test_acc}\\t\\t{model_accuracy}\")\n",
    "\n",
    "            logger.info(f\"{'>>'*30} Loss {'<<'*30}\")\n",
    "            logger.info(f\"Diff test train accuracy: [{diff_test_train_acc}].\") \n",
    "            logger.info(f\"Train root mean squared error: [{train_rmse}].\")\n",
    "            logger.info(f\"Test root mean squared error: [{test_rmse}].\")\n",
    "\n",
    "\n",
    "            #if model accuracy is greater than base accuracy and train and test score is within certain thershold\n",
    "            #we will accept that model as accepted model\n",
    "            if model_accuracy >= base_accuracy and diff_test_train_acc < 0.05:\n",
    "                base_accuracy = model_accuracy\n",
    "                metric_info_artifact = MetricInfoArtifact(model_name=model_name,\n",
    "                                                        model_object=model,\n",
    "                                                        train_rmse=train_rmse,\n",
    "                                                        test_rmse=test_rmse,\n",
    "                                                        train_accuracy=train_acc,\n",
    "                                                        test_accuracy=test_acc,\n",
    "                                                        model_accuracy=model_accuracy,\n",
    "                                                        index_number=index_number)\n",
    "\n",
    "                logger.info(f\"Acceptable model found {metric_info_artifact}. \")\n",
    "            index_number += 1\n",
    "        if metric_info_artifact is None:\n",
    "            logger.info(f\"No model found with higher accuracy than base accuracy\")\n",
    "        return metric_info_artifact\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import log\n",
    "import importlib\n",
    "from pyexpat import model\n",
    "import numpy as np\n",
    "import yaml\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-30 14:25:15,499: INFO: common]: yaml file: config\\config.yaml loaded successfully\n",
      "[2023-03-30 14:25:15,501: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2023-03-30 14:25:15,503: INFO: common]: created directory at: artifacts\n",
      "[2023-03-30 14:25:15,513: INFO: common]: yaml file: config\\config.yaml loaded successfully\n",
      "[2023-03-30 14:25:15,516: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2023-03-30 14:25:15,518: INFO: common]: created directory at: artifacts\n",
      "[2023-03-30 14:25:15,520: INFO: 714097908]: training started \n",
      "[2023-03-30 14:25:15,522: INFO: 2388430155]: loading training and testing data sets\n",
      "[2023-03-30 14:25:15,527: INFO: 2388430155]: train and test data generated for data training\n",
      "[2023-03-30 14:25:15,529: INFO: 2388430155]: initializing model by using config filepath\n",
      "[2023-03-30 14:25:15,535: INFO: 2388430155]: expected accuracy:0.6\n",
      "[2023-03-30 14:25:15,536: INFO: 2157547986]: importing module:sklearn.linear_model with class:LinearRegression\n",
      "[2023-03-30 14:25:15,537: INFO: 2157547986]: Executing:$ LinearRegression().fit_intercept=True\n",
      "[2023-03-30 14:25:15,538: INFO: 2157547986]: importing module:sklearn.ensemble with class:RandomForestRegressor\n",
      "[2023-03-30 14:25:15,540: INFO: 2157547986]: Executing:$ RandomForestRegressor(min_samples_leaf=3).min_samples_leaf=3\n",
      "[2023-03-30 14:25:15,543: INFO: 2157547986]: importing module:sklearn.model_selection with class:GridSearchCV\n",
      "[2023-03-30 14:25:15,549: INFO: 2157547986]: Executing:$ GridSearchCV(cv=5, estimator=LinearRegression(),\n",
      "             param_grid={'fit_intercept': [True, False]}).cv=5\n",
      "[2023-03-30 14:25:15,552: INFO: 2157547986]: Executing:$ GridSearchCV(cv=5, estimator=LinearRegression(),\n",
      "             param_grid={'fit_intercept': [True, False]}, verbose=2).verbose=2\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[2023-03-30 14:25:15,599: INFO: 2157547986]: importing module:sklearn.model_selection with class:GridSearchCV\n",
      "[2023-03-30 14:25:15,602: INFO: 2157547986]: Executing:$ GridSearchCV(cv=5, estimator=RandomForestRegressor(min_samples_leaf=3),\n",
      "             param_grid={'min_samples_leaf': [6]}).cv=5\n",
      "[2023-03-30 14:25:15,604: INFO: 2157547986]: Executing:$ GridSearchCV(cv=5, estimator=RandomForestRegressor(min_samples_leaf=3),\n",
      "             param_grid={'min_samples_leaf': [6]}, verbose=2).verbose=2\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END .................................min_samples_leaf=6; total time=   0.2s\n",
      "[CV] END .................................min_samples_leaf=6; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=6; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=6; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=6; total time=   0.1s\n",
      "[2023-03-30 14:25:17,137: INFO: 2157547986]: Acceptable model found:{grid_search_best_model}\n",
      "[2023-03-30 14:25:17,138: INFO: 2157547986]: Acceptable model found:{grid_search_best_model}\n",
      "[2023-03-30 14:25:17,139: INFO: 2157547986]: best model found:GridSearchedBestModel(model_serial_number='module_1', model=RandomForestRegressor(min_samples_leaf=3), best_model=RandomForestRegressor(min_samples_leaf=6), best_parameters={'min_samples_leaf': 6}, best_score=0.8455995750497621)\n",
      "[2023-03-30 14:25:17,140: INFO: 2388430155]: Best model found on training dataset: None\n",
      "[2023-03-30 14:25:17,141: INFO: 2388430155]: Extracting trained model list.\n",
      "[2023-03-30 14:25:17,142: INFO: 2388430155]: Evaluation all trained model on training and testing dataset both\n",
      "[2023-03-30 14:25:17,143: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Started evaluating model: [LinearRegression] <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,147: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Score <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,147: INFO: 3603608369]: Train Score\t\t Test Score\t\t Average Score\n",
      "[2023-03-30 14:25:17,148: INFO: 3603608369]: 0.7417818556014169\t\t 0.7845254663338332\t\t0.762555152321238\n",
      "[2023-03-30 14:25:17,149: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Loss <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,150: INFO: 3603608369]: Diff test train accuracy: [0.04274361073241639].\n",
      "[2023-03-30 14:25:17,151: INFO: 3603608369]: Train root mean squared error: [6153.610712758158].\n",
      "[2023-03-30 14:25:17,152: INFO: 3603608369]: Test root mean squared error: [5611.119130603219].\n",
      "[2023-03-30 14:25:17,153: INFO: 3603608369]: Acceptable model found MetricInfoArtifact(model_name='LinearRegression(fit_intercept=False)', model_object=LinearRegression(fit_intercept=False), train_rmse=6153.610712758158, test_rmse=5611.119130603219, train_accuracy=0.7417818556014169, test_accuracy=0.7845254663338332, model_accuracy=0.762555152321238, index_number=0). \n",
      "[2023-03-30 14:25:17,155: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Started evaluating model: [RandomForestRegressor] <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,192: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Score <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,193: INFO: 3603608369]: Train Score\t\t Test Score\t\t Average Score\n",
      "[2023-03-30 14:25:17,195: INFO: 3603608369]: 0.8974970174091566\t\t 0.8956923482822609\t\t0.8965937747345186\n",
      "[2023-03-30 14:25:17,196: INFO: 3603608369]: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Loss <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "[2023-03-30 14:25:17,197: INFO: 3603608369]: Diff test train accuracy: [0.0018046691268956971].\n",
      "[2023-03-30 14:25:17,198: INFO: 3603608369]: Train root mean squared error: [3877.0811566116545].\n",
      "[2023-03-30 14:25:17,199: INFO: 3603608369]: Test root mean squared error: [3903.998110080588].\n",
      "[2023-03-30 14:25:17,201: INFO: 3603608369]: Acceptable model found MetricInfoArtifact(model_name='RandomForestRegressor(min_samples_leaf=6)', model_object=RandomForestRegressor(min_samples_leaf=6), train_rmse=3877.0811566116545, test_rmse=3903.998110080588, train_accuracy=0.8974970174091566, test_accuracy=0.8956923482822609, model_accuracy=0.8965937747345186, index_number=1). \n",
      "[2023-03-30 14:25:17,202: INFO: 2388430155]: Best found model on both training and testing dataset.\n",
      "[2023-03-30 14:25:17,204: INFO: 2388430155]: Saving model at path: artifacts\\data_model_trainer\\trained_model\\model.pkl\n",
      "[2023-03-30 14:25:17,383: INFO: 2388430155]: Saving model at path: artifacts\\data_model_trainer\\trained_model\\model.pkl is successfully done\n",
      "[2023-03-30 14:25:17,385: INFO: 714097908]: training completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    model_trainer=ModelTrainer(config=config)\n",
    "    logger.info(\"training started \")\n",
    "    model_trainer.get_trained_model()\n",
    "    logger.info(\"training completed\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\analyzers\\__init__.py:3: UserWarning: analyzers are deprecated, use metrics instead\n",
      "  warnings.warn(\"analyzers are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\model_profile\\__init__.py:8: UserWarning: model profiles are deprecated, use metrics instead\n",
      "  warnings.warn(\"model profiles are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\dashboard\\__init__.py:8: UserWarning: dashboards are deprecated, use metrics instead\n",
      "  warnings.warn(\"dashboards are deprecated, use metrics instead\")\n"
     ]
    }
   ],
   "source": [
    "from insurence_premium.components.data_model_trainer import ModelTrainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from insure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurence_premium.entity.model_entity import GridSearchedBestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insurence_premium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\analyzers\\__init__.py:3: UserWarning: analyzers are deprecated, use metrics instead\n",
      "  warnings.warn(\"analyzers are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\model_profile\\__init__.py:8: UserWarning: model profiles are deprecated, use metrics instead\n",
      "  warnings.warn(\"model profiles are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\dashboard\\__init__.py:8: UserWarning: dashboards are deprecated, use metrics instead\n",
      "  warnings.warn(\"dashboards are deprecated, use metrics instead\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'insurence_premium.entiy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_model_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelTrainer\n",
      "File \u001b[1;32m<frozen zipimport>:259\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\insurencepremium-0.0.1-py3.8.egg\\insurence_premium\\components\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m DataValidation\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_transformation\u001b[39;00m \u001b[39mimport\u001b[39;00m  DataTransformation\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_model_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelTrainer ,HousingEstimatorModel\n",
      "File \u001b[1;32m<frozen zipimport>:259\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\insurencepremium-0.0.1-py3.8.egg\\insurence_premium\\components\\data_model_trainer.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigurationManager\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mentiy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_entity\u001b[39;00m \u001b[39mimport\u001b[39;00m MetricInfoArtifact ,BestModel,GridSearchedBestModel,InitialisedModelDetail\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m save_object ,load_object\n\u001b[0;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHousingEstimatorModel\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'insurence_premium.entiy'"
     ]
    }
   ],
   "source": [
    "from insurence_premium.components.data_model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\analyzers\\__init__.py:3: UserWarning: analyzers are deprecated, use metrics instead\n",
      "  warnings.warn(\"analyzers are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\model_profile\\__init__.py:8: UserWarning: model profiles are deprecated, use metrics instead\n",
      "  warnings.warn(\"model profiles are deprecated, use metrics instead\")\n",
      "c:\\Users\\somit\\Downloads\\project_ineuron\\insurence_premium_prediction\\env\\lib\\site-packages\\evidently\\dashboard\\__init__.py:8: UserWarning: dashboards are deprecated, use metrics instead\n",
      "  warnings.warn(\"dashboards are deprecated, use metrics instead\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'insurence_premium.entiy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_model_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelTrainer\n",
      "File \u001b[1;32m~\\Downloads\\project_ineuron\\insurence_premium_prediction\\src\\insurence_premium\\components\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m DataValidation\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_transformation\u001b[39;00m \u001b[39mimport\u001b[39;00m  DataTransformation\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_model_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelTrainer ,HousingEstimatorModel\n",
      "File \u001b[1;32m~\\Downloads\\project_ineuron\\insurence_premium_prediction\\src\\insurence_premium\\components\\data_model_trainer.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigurationManager\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mentiy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_entity\u001b[39;00m \u001b[39mimport\u001b[39;00m MetricInfoArtifact ,BestModel,GridSearchedBestModel,InitialisedModelDetail\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minsurence_premium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m save_object ,load_object\n\u001b[0;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHousingEstimatorModel\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'insurence_premium.entiy'"
     ]
    }
   ],
   "source": [
    "from insurence_premium.components.data_model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurence_premium.entity.model_entity import MetricInfoArtifact ,InitialisedModelDetail ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83a00447bd124a9a34ce6d3eb750f5d038b15e4d9b9f3216035bc8ab927c8f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
